{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/anindya/Submission/text2sql/text2sql\n"
     ]
    }
   ],
   "source": [
    "# cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuner\n",
    "\n",
    "premsql fine-tuner is the module that fine-tunes model for text to SQL tasks. We support the following ways of fine-tuning\n",
    "\n",
    "1. Full fine-tuning \n",
    "2. PEFT using LoRA\n",
    "3. PEFT using QLoRA\n",
    "\n",
    "You can even make your own custom fine-tuning pipeline using our components and the set of tools that premsql provides. This tutorial expects you to know the following topics. \n",
    "\n",
    "1. [premsql datasets](/examples/datasets.ipynb)\n",
    "2. [premsql generators](/examples/generators.ipynb)\n",
    "3. [premsql evaluators](/examples/evaluation.ipynb)\n",
    "4. [premsql error handling datasets](/examples/error_dataset.ipynb)\n",
    "\n",
    "Additionally it would be great if you have some ideas on how huggingface transformers [TRL](https://huggingface.co/docs/trl/en/index) library works. We start by importing some packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/deep/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-07 10:41:00,820] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/deep/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/deep/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, input, weight, bias=None):\n",
      "/root/miniconda3/envs/deep/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n"
     ]
    }
   ],
   "source": [
    "from premsql.datasets import (\n",
    "    BirdDataset,\n",
    "    SpiderUnifiedDataset,\n",
    "    DomainsDataset,\n",
    "    GretelAIDataset\n",
    ")\n",
    "\n",
    "from premsql.evaluator.from_sqlite import SQLiteExecutor\n",
    "from premsql.datasets import Text2SQLDataset\n",
    "from premsql.tuner.peft import Text2SQLPeftTuner\n",
    "from premsql.datasets.error_dataset import ErrorDatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/root/anindya/text2sql/data\"\n",
    "model_name_or_path = \"premai-io/prem-1B-SQL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining different datasets\n",
    "\n",
    "Now first we need some training datasets. In our tutorial, we are using small subsets (only for demo purposes, during actual fine-tuning you should be using the full dataset) of various datasets that prem sql provides. We start off by importing the BirdBench training datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 10:41:16,255 - [BIRD-DATASET] - INFO - Loaded Bird Dataset\n",
      "2024-09-07 10:41:16,257 - [BIRD-DATASET] - INFO - Setting up Bird Dataset\n",
      "Applying prompt: 100%|██████████| 100/100 [00:00<00:00, 3519.80it/s]\n",
      "2024-09-07 10:41:16,891 - [DATASET] - INFO - Casted dataset with model chat template\n",
      "2024-09-07 10:41:16,892 - [DATASET] - INFO - Starting Tokenization ...\n",
      "Tokenizing: 100%|██████████| 100/100 [00:00<00:00, 188.71it/s]\n",
      "Tokenizing: 100%|██████████| 100/100 [00:00<00:00, 199.78it/s]\n"
     ]
    }
   ],
   "source": [
    "bird_train = BirdDataset(split=\"train\", dataset_folder=path).setup_dataset(\n",
    "    num_rows=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followed by we then load the Spider dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 10:41:44,000 - [SPIDER-DATASET] - INFO - Loaded Spider Dataset\n",
      "2024-09-07 10:41:44,005 - [SPIDER-DATASET] - INFO - Setting up Spider Dataset\n",
      "Applying prompt: 100%|██████████| 100/100 [00:00<00:00, 4144.69it/s]\n",
      "2024-09-07 10:41:44,636 - [DATASET] - INFO - Casted dataset with model chat template\n",
      "2024-09-07 10:41:44,637 - [DATASET] - INFO - Starting Tokenization ...\n",
      "Tokenizing: 100%|██████████| 100/100 [00:00<00:00, 399.31it/s]\n",
      "Tokenizing: 100%|██████████| 100/100 [00:00<00:00, 436.83it/s]\n"
     ]
    }
   ],
   "source": [
    "spider_train = SpiderUnifiedDataset(split=\"train\", dataset_folder=\"./data\").setup_dataset(\n",
    "    num_rows=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the domains dataset here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 10:42:00,249 - [DOMAINS-DATASET] - INFO - Loaded Domains Dataset\n",
      "2024-09-07 10:42:00,252 - [DOMAINS-DATASET] - INFO - Setting up Domains Dataset\n",
      "Applying prompt: 100%|██████████| 100/100 [00:00<00:00, 2671.91it/s]\n",
      "2024-09-07 10:42:00,681 - [DATASET] - INFO - Casted dataset with model chat template\n",
      "2024-09-07 10:42:00,682 - [DATASET] - INFO - Starting Tokenization ...\n",
      "Tokenizing: 100%|██████████| 100/100 [00:00<00:00, 226.39it/s]\n",
      "Tokenizing: 100%|██████████| 100/100 [00:00<00:00, 241.73it/s]\n"
     ]
    }
   ],
   "source": [
    "domains_dataset = DomainsDataset(split=\"train\", dataset_folder=\"./data\").setup_dataset(\n",
    "    num_rows=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load the Gretel AI synthetic Text to SQL dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying prompt: 100%|██████████| 100/100 [00:00<00:00, 162130.03it/s]\n",
      "2024-09-07 10:42:14,958 - [DATASET] - INFO - Casted dataset with model chat template\n",
      "2024-09-07 10:42:14,958 - [DATASET] - INFO - Starting Tokenization ...\n",
      "Tokenizing: 100%|██████████| 100/100 [00:00<00:00, 517.27it/s]\n",
      "Tokenizing: 100%|██████████| 100/100 [00:00<00:00, 579.19it/s]\n"
     ]
    }
   ],
   "source": [
    "gertelai_dataset = GretelAIDataset(split=\"train\", dataset_folder=\"./data\",).setup_dataset(\n",
    "    num_rows=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not the least we also load an error dataset. You can learn more about error handling dataset [here](/examples/error_dataset.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 10:42:28,011 - [DATASET] - INFO - Casted dataset with model chat template\n",
      "2024-09-07 10:42:28,012 - [DATASET] - INFO - Starting Tokenization ...\n",
      "Tokenizing: 100%|██████████| 10/10 [00:00<00:00, 160.95it/s]\n",
      "Tokenizing: 100%|██████████| 10/10 [00:00<00:00, 180.55it/s]\n"
     ]
    }
   ],
   "source": [
    "existing_error_dataset = ErrorDatasetGenerator.from_existing(\n",
    "    experiment_name=\"testing_error_gen\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE:\n",
    "\n",
    "Since this tutorial is about fine-tuning using PEFT (using LoRA), so internally this workflow uses TRL. So the datasets we are instantiating do need to be tokenized, since TRL will be tokenizing under the hood. \n",
    "\n",
    "\n",
    "Now let's Merge all the datasets. We can pack different datasets into one single entity just like this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = [\n",
    "    *spider_train,\n",
    "    *bird_train,\n",
    "    *domains_dataset,\n",
    "    *gertelai_dataset,\n",
    "    *existing_error_dataset\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally we also initialize the BirdBench validation dataset so that we can use it during the time of validation. \n",
    "\n",
    "Text-to-SQL validation methods are different from normal LLM fine-tuning tasks validation processes. Here we execute generated SQL on the database and check if it matches with the ground truth tables or not. So premsql offers a custom and a robust [huggingface callback](/premsql/tuner/callback.py) that helps you to evaluate during each evaluate steps of model training which is the same evaluation method we do using evaluators. \n",
    "\n",
    "So in this case, all you need to do is to define your validation datasets and thats it, our callback will take care of rest of things. If you are unfamiliar with the syntaxes below, you should check out [datasets](/examples/datasets.ipynb) and [evaluator](/examples/evaluation.ipynb) section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 10:43:00,302 - [BIRD-DATASET] - INFO - Loaded Bird Dataset\n",
      "2024-09-07 10:43:00,303 - [BIRD-DATASET] - INFO - Setting up Bird Dataset\n",
      "Applying prompt: 100%|██████████| 10/10 [00:00<00:00, 1762.53it/s]\n"
     ]
    }
   ],
   "source": [
    "bird_dev = Text2SQLDataset(dataset_name=\"bird\", split=\"validation\", dataset_folder=path).setup_dataset(\n",
    "    num_rows=10,\n",
    "    filter_by=(\"difficulty\", \"challenging\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have set up everything, we need to initialize our tuner class. To initialize our tuner, we need to provide a `model_name_or_path` which will load the model (which is to be fine-tuned) and also provide an `experiment_name` which will save all the logs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 10:43:05,347 - [LORA-FINETUNE] - WARNING - Setting up Pretrained-Model: premai-io/prem-1B-SQL\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.82s/it]\n"
     ]
    }
   ],
   "source": [
    "tuner = Text2SQLPeftTuner(\n",
    "    model_name_or_path=model_name_or_path,\n",
    "    experiment_name=\"lora_tuning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we call the train functions to provide the following things:\n",
    "\n",
    "1. train_datasets: The merged datasets which will be used for training\n",
    "2. output_dir: the output directory in which model weights will be stored\n",
    "3. num_train_epochs: Number of epochs\n",
    "4. per_device_train_batch_size: The train batch size per device \n",
    "5. gradient_accumulation_steps: Number of gradient accumulation steps\n",
    "6. evaluation_dataset: The evaluation dataset. It can also be None, and in that case it will not do evaluation steps during fine-tuning.\n",
    "7. eval_steps: After how many steps we need to start evaluation. \n",
    "8. max_seq_length: Maximum permissible sequence length of the model. \n",
    "9. executor: Only provide an [executor](/examples/evaluation.ipynb) when you have defined a evaluation_dataset. \n",
    "10. filter_eval_results_by: Make sure the filter key and filter value is present inside the dataset. This will filter the results out. In our case we are filtering by difficulty to only evaluate on challenging data points.\n",
    "\n",
    "Additionally you can provide your additional parameters (which should be compatible with [transformers TrainingArguments](https://huggingface.co/docs/transformers/v4.44.2/en/main_classes/trainer#transformers.TrainingArguments)) in form of **kwargs and it will override any other default settings. Now let's use this information to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.train(\n",
    "    train_datasets=merged_dataset,\n",
    "    output_dir=\"./output\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    evaluation_dataset=bird_dev,\n",
    "    eval_steps=100,\n",
    "    max_seq_length=1024,\n",
    "    executor=SQLiteExecutor(),\n",
    "    filter_eval_results_by=(\"difficulty\", \"challenging\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will start training the model. And you will see all the model outputs being stored inside `./output` and all the model fine-tuning logs being stored inside `./experiments/train/<experiment-name>` directory. You can checkout our [fine-tuning using LoRA script](/examples/lora_tuning.py) for an end to end example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
