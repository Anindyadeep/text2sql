{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/anindya/Submission/text2sql/text2sql\n"
     ]
    }
   ],
   "source": [
    "# cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/deep/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-07 10:41:00,820] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/deep/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/deep/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, input, weight, bias=None):\n",
      "/root/miniconda3/envs/deep/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n"
     ]
    }
   ],
   "source": [
    "from premsql.datasets import (\n",
    "    BirdDataset,\n",
    "    SpiderUnifiedDataset,\n",
    "    DomainsDataset,\n",
    "    GretelAIDataset\n",
    ")\n",
    "\n",
    "from premsql.evaluator.from_sqlite import SQLiteExecutor\n",
    "from premsql.datasets import Text2SQLDataset\n",
    "from premsql.tuner.peft import Text2SQLPeftTuner\n",
    "from premsql.datasets.error_dataset import ErrorDatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/root/anindya/text2sql/data\"\n",
    "model_name_or_path = \"premai-io/prem-1B-SQL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 10:41:16,255 - [BIRD-DATASET] - INFO - Loaded Bird Dataset\n",
      "2024-09-07 10:41:16,257 - [BIRD-DATASET] - INFO - Setting up Bird Dataset\n",
      "Applying prompt: 100%|██████████| 100/100 [00:00<00:00, 3519.80it/s]\n",
      "2024-09-07 10:41:16,891 - [DATASET] - INFO - Casted dataset with model chat template\n",
      "2024-09-07 10:41:16,892 - [DATASET] - INFO - Starting Tokenization ...\n",
      "Tokenizing: 100%|██████████| 100/100 [00:00<00:00, 188.71it/s]\n",
      "Tokenizing: 100%|██████████| 100/100 [00:00<00:00, 199.78it/s]\n"
     ]
    }
   ],
   "source": [
    "bird_train = BirdDataset(split=\"train\", dataset_folder=path).setup_dataset(\n",
    "    num_rows=100,\n",
    "    model_name_or_path=model_name_or_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 10:41:44,000 - [SPIDER-DATASET] - INFO - Loaded Spider Dataset\n",
      "2024-09-07 10:41:44,005 - [SPIDER-DATASET] - INFO - Setting up Spider Dataset\n",
      "Applying prompt: 100%|██████████| 100/100 [00:00<00:00, 4144.69it/s]\n",
      "2024-09-07 10:41:44,636 - [DATASET] - INFO - Casted dataset with model chat template\n",
      "2024-09-07 10:41:44,637 - [DATASET] - INFO - Starting Tokenization ...\n",
      "Tokenizing: 100%|██████████| 100/100 [00:00<00:00, 399.31it/s]\n",
      "Tokenizing: 100%|██████████| 100/100 [00:00<00:00, 436.83it/s]\n"
     ]
    }
   ],
   "source": [
    "spider_train = SpiderUnifiedDataset(split=\"train\", dataset_folder=\"./data\").setup_dataset(\n",
    "    num_rows=100,\n",
    "    model_name_or_path=model_name_or_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 10:42:00,249 - [DOMAINS-DATASET] - INFO - Loaded Domains Dataset\n",
      "2024-09-07 10:42:00,252 - [DOMAINS-DATASET] - INFO - Setting up Domains Dataset\n",
      "Applying prompt: 100%|██████████| 100/100 [00:00<00:00, 2671.91it/s]\n",
      "2024-09-07 10:42:00,681 - [DATASET] - INFO - Casted dataset with model chat template\n",
      "2024-09-07 10:42:00,682 - [DATASET] - INFO - Starting Tokenization ...\n",
      "Tokenizing: 100%|██████████| 100/100 [00:00<00:00, 226.39it/s]\n",
      "Tokenizing: 100%|██████████| 100/100 [00:00<00:00, 241.73it/s]\n"
     ]
    }
   ],
   "source": [
    "domains_dataset = DomainsDataset(split=\"train\", dataset_folder=\"./data\").setup_dataset(\n",
    "    num_rows=100,\n",
    "    model_name_or_path=model_name_or_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying prompt: 100%|██████████| 100/100 [00:00<00:00, 162130.03it/s]\n",
      "2024-09-07 10:42:14,958 - [DATASET] - INFO - Casted dataset with model chat template\n",
      "2024-09-07 10:42:14,958 - [DATASET] - INFO - Starting Tokenization ...\n",
      "Tokenizing: 100%|██████████| 100/100 [00:00<00:00, 517.27it/s]\n",
      "Tokenizing: 100%|██████████| 100/100 [00:00<00:00, 579.19it/s]\n"
     ]
    }
   ],
   "source": [
    "gertelai_dataset = GretelAIDataset(split=\"train\", dataset_folder=\"./data\",).setup_dataset(\n",
    "    num_rows=100,\n",
    "    model_name_or_path=model_name_or_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 10:42:28,011 - [DATASET] - INFO - Casted dataset with model chat template\n",
      "2024-09-07 10:42:28,012 - [DATASET] - INFO - Starting Tokenization ...\n",
      "Tokenizing: 100%|██████████| 10/10 [00:00<00:00, 160.95it/s]\n",
      "Tokenizing: 100%|██████████| 10/10 [00:00<00:00, 180.55it/s]\n"
     ]
    }
   ],
   "source": [
    "existing_error_dataset = ErrorDatasetGenerator.from_existing(\n",
    "    experiment_name=\"testing_error_gen\",\n",
    "    tokenize_model_name_or_path=model_name_or_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = [\n",
    "    *spider_train,\n",
    "    *bird_train,\n",
    "    *domains_dataset,\n",
    "    *gertelai_dataset,\n",
    "    *existing_error_dataset\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 10:43:00,302 - [BIRD-DATASET] - INFO - Loaded Bird Dataset\n",
      "2024-09-07 10:43:00,303 - [BIRD-DATASET] - INFO - Setting up Bird Dataset\n",
      "Applying prompt: 100%|██████████| 10/10 [00:00<00:00, 1762.53it/s]\n"
     ]
    }
   ],
   "source": [
    "bird_dev = Text2SQLDataset(dataset_name=\"bird\", split=\"validation\", dataset_folder=path).setup_dataset(\n",
    "    num_rows=10,\n",
    "    filter_by=(\"difficulty\", \"challenging\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 10:43:05,347 - [LORA-FINETUNE] - WARNING - Setting up Pretrained-Model: premai-io/prem-1B-SQL\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.82s/it]\n"
     ]
    }
   ],
   "source": [
    "tuner = Text2SQLPeftTuner(\n",
    "    model_name_or_path=model_name_or_path,\n",
    "    experiment_name=\"lora_tuning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.train(\n",
    "    train_datasets=merged_dataset,\n",
    "    output_dir=\"./output\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    evaluation_dataset=bird_dev,\n",
    "    eval_steps=100,\n",
    "    max_seq_length=1024,\n",
    "    executor=SQLiteExecutor(),\n",
    "    filter_eval_results_by=(\"difficulty\", \"challenging\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
