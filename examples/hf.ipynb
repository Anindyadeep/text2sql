{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "\n",
    "# Run this incase if you have not installed the repo as a package but still\n",
    "# want to run this notebook\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "dir_to_use = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(dir_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Defog AI SQL Coder on BIRDBench dataset\n",
    "\n",
    "In this example, we are going to show how to evaluate Open Source LLMs using text2sql library. We are going to evaluate Defog AI's latest [text2sql model](https://huggingface.co/defog/llama-3-sqlcoder-8b). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anindya/miniconda3/envs/prem/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sqlparse\n",
    "\n",
    "from text2sql.eval.dataset.bird import BirdBenchEvalDataset\n",
    "from text2sql.eval.settings import SQLGeneratorConfig, ModelConfig\n",
    "from text2sql.eval.generator import SQLGeneratorFromModel\n",
    "from text2sql.eval.executor.bird.acc import BirdExecutorAcc\n",
    "from text2sql.eval.executor.bird.ves import BirdExecutorVES\n",
    "\n",
    "config = SQLGeneratorConfig()\n",
    "model_config = ModelConfig(\n",
    "    model_name=\"defog/llama-3-sqlcoder-8b\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=256,\n",
    "    is_instruct=True\n",
    ")\n",
    "\n",
    "eval_dataset = BirdBenchEvalDataset(config=config)\n",
    "\n",
    "def postprocess(input_string: str):\n",
    "    sql_start_keywords = [\n",
    "        r\"\\bSELECT\\b\",\n",
    "        r\"\\bINSERT\\b\",\n",
    "        r\"\\bUPDATE\\b\",\n",
    "        r\"\\bDELETE\\b\",\n",
    "        r\"\\bWITH\\b\",\n",
    "    ]\n",
    "\n",
    "    sql_start_pattern = re.compile(\"|\".join(sql_start_keywords), re.IGNORECASE)\n",
    "    match = sql_start_pattern.search(input_string)\n",
    "\n",
    "    if match:\n",
    "        start_pos = match.start()\n",
    "        sql_statement = input_string[start_pos:]\n",
    "        return sqlparse.format(sql_statement)\n",
    "    else:\n",
    "        return sqlparse.format(input_string)\n",
    "\n",
    "\n",
    "def run(dataset, difficulty, num_rows):\n",
    "    filter_by = (\"difficulty\", difficulty)\n",
    "    processed = dataset.process_and_filter(\n",
    "        num_rows=num_rows, \n",
    "        filter_by=filter_by\n",
    "    ).apply_prompt(apply_knowledge=True)\n",
    "\n",
    "    \n",
    "    config = SQLGeneratorConfig(model_name=f\"defog_{difficulty}_{num_rows}\")\n",
    "    client = SQLGeneratorFromModel(\n",
    "        generator_config=config,\n",
    "        engine_config=model_config\n",
    "    )\n",
    "    acc = BirdExecutorAcc(generator_config=config)\n",
    "    ves = BirdExecutorVES(generator_config=config)\n",
    "\n",
    "    data_with_gen = client.generate_and_save_results(\n",
    "        data=processed, \n",
    "        force=True,\n",
    "        postprocess=postprocess\n",
    "    )\n",
    "\n",
    "    acc.execute(model_responses=data_with_gen, filter_used=filter_by)\n",
    "    ves.execute(model_responses=data_with_gen, filter_used=filter_by)\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 07:06:42,980 - text2sql-eval - INFO - ./data/eval/ is not empty. Use force=True to re-download and overwrite the contents.\n",
      "2024-08-05 07:06:42,980 - text2sql-eval - INFO - ./data/eval/ is not empty. Use force=True to re-download and overwrite the contents.\n",
      "/home/anindya/miniconda3/envs/prem/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.22s/it]\n",
      "/home/anindya/miniconda3/envs/prem/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/anindya/miniconda3/envs/prem/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "100%|██████████| 100/100 [03:14<00:00,  1.94s/it]\n",
      "2024-08-05 07:10:03,050 - text2sql-eval - INFO - all responses written to ./experiments/eval/prem_defog_simple_100/predict_dev.json\n",
      "2024-08-05 07:10:03,050 - text2sql-eval - INFO - all responses written to ./experiments/eval/prem_defog_simple_100/predict_dev.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>  ./experiments/eval/prem_defog_simple_100 acc_simple.json\n",
      "=====================   ACCURACY    =====================\n",
      "+-------------+-------------------+-------------------+\n",
      "| Category    |   num_correct (%) |   total questions |\n",
      "+=============+===================+===================+\n",
      "| simple      |                18 |               100 |\n",
      "+-------------+-------------------+-------------------+\n",
      "| overall     |                18 |               100 |\n",
      "+-------------+-------------------+-------------------+\n",
      "| moderate    |                 0 |                 0 |\n",
      "+-------------+-------------------+-------------------+\n",
      "| challenging |                 0 |                 0 |\n",
      "+-------------+-------------------+-------------------+\n",
      "=====================   VES    =====================\n",
      "+-------------+-----------+-------------------+\n",
      "| Category    |   VES (%) |   total questions |\n",
      "+=============+===========+===================+\n",
      "| simple      |   21.8705 |               100 |\n",
      "+-------------+-----------+-------------------+\n",
      "| overall     |   21.8705 |               100 |\n",
      "+-------------+-----------+-------------------+\n",
      "| moderate    |    0      |                 0 |\n",
      "+-------------+-----------+-------------------+\n",
      "| challenging |    0      |                 0 |\n",
      "+-------------+-----------+-------------------+\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run(eval_dataset, difficulty=\"simple\", num_rows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 07:43:27,148 - text2sql-eval - INFO - ./data/eval/ is not empty. Use force=True to re-download and overwrite the contents.\n",
      "2024-08-05 07:43:27,148 - text2sql-eval - INFO - ./data/eval/ is not empty. Use force=True to re-download and overwrite the contents.\n",
      "/home/anindya/miniconda3/envs/prem/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.08s/it]\n",
      "/home/anindya/miniconda3/envs/prem/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/anindya/miniconda3/envs/prem/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "100%|██████████| 100/100 [03:49<00:00,  2.29s/it]\n",
      "2024-08-05 07:47:25,656 - text2sql-eval - INFO - all responses written to ./experiments/eval/prem_defog_moderate_100/predict_dev.json\n",
      "2024-08-05 07:47:25,656 - text2sql-eval - INFO - all responses written to ./experiments/eval/prem_defog_moderate_100/predict_dev.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>  ./experiments/eval/prem_defog_moderate_100 acc_moderate.json\n",
      "=====================   ACCURACY    =====================\n",
      "+-------------+-------------------+-------------------+\n",
      "| Category    |   num_correct (%) |   total questions |\n",
      "+=============+===================+===================+\n",
      "| moderate    |                17 |               100 |\n",
      "+-------------+-------------------+-------------------+\n",
      "| overall     |                17 |               100 |\n",
      "+-------------+-------------------+-------------------+\n",
      "| simple      |                 0 |                 0 |\n",
      "+-------------+-------------------+-------------------+\n",
      "| challenging |                 0 |                 0 |\n",
      "+-------------+-------------------+-------------------+\n",
      "=====================   VES    =====================\n",
      "+-------------+-----------+-------------------+\n",
      "| Category    |   VES (%) |   total questions |\n",
      "+=============+===========+===================+\n",
      "| moderate    |   22.2302 |               100 |\n",
      "+-------------+-----------+-------------------+\n",
      "| overall     |   22.2302 |               100 |\n",
      "+-------------+-----------+-------------------+\n",
      "| simple      |    0      |                 0 |\n",
      "+-------------+-----------+-------------------+\n",
      "| challenging |    0      |                 0 |\n",
      "+-------------+-----------+-------------------+\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run(eval_dataset, difficulty=\"moderate\", num_rows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 07:47:34,755 - text2sql-eval - INFO - ./data/eval/ is not empty. Use force=True to re-download and overwrite the contents.\n",
      "2024-08-05 07:47:34,755 - text2sql-eval - INFO - ./data/eval/ is not empty. Use force=True to re-download and overwrite the contents.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.06s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "100%|██████████| 100/100 [04:10<00:00,  2.51s/it]\n",
      "2024-08-05 07:51:54,827 - text2sql-eval - INFO - all responses written to ./experiments/eval/prem_defog_challenging_100/predict_dev.json\n",
      "2024-08-05 07:51:54,827 - text2sql-eval - INFO - all responses written to ./experiments/eval/prem_defog_challenging_100/predict_dev.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>  ./experiments/eval/prem_defog_challenging_100 acc_challenging.json\n",
      "=====================   ACCURACY    =====================\n",
      "+-------------+-------------------+-------------------+\n",
      "| Category    |   num_correct (%) |   total questions |\n",
      "+=============+===================+===================+\n",
      "| challenging |                27 |               100 |\n",
      "+-------------+-------------------+-------------------+\n",
      "| overall     |                27 |               100 |\n",
      "+-------------+-------------------+-------------------+\n",
      "| simple      |                 0 |                 0 |\n",
      "+-------------+-------------------+-------------------+\n",
      "| moderate    |                 0 |                 0 |\n",
      "+-------------+-------------------+-------------------+\n",
      "=====================   VES    =====================\n",
      "+-------------+-----------+-------------------+\n",
      "| Category    |   VES (%) |   total questions |\n",
      "+=============+===========+===================+\n",
      "| challenging |   27.9221 |               100 |\n",
      "+-------------+-----------+-------------------+\n",
      "| overall     |   27.9221 |               100 |\n",
      "+-------------+-----------+-------------------+\n",
      "| simple      |    0      |                 0 |\n",
      "+-------------+-----------+-------------------+\n",
      "| moderate    |    0      |                 0 |\n",
      "+-------------+-----------+-------------------+\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run(eval_dataset, difficulty=\"challenging\", num_rows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
