{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/anindya/Submission/text2sql/text2sql\n"
     ]
    }
   ],
   "source": [
    "# cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling Datasets and Prompts\n",
    "\n",
    "In this section we are going to discuss on how you can create error handling prompt which you can pass it to the models during inference for self-correction from errors, or make error handling prompts to fine-tune your models furthur to make them learn how to handle errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/deep/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from premsql.datasets.error_dataset import ErrorDatasetGenerator\n",
    "from premsql.generators.huggingface import Text2SQLGeneratorHF\n",
    "from premsql.evaluator.from_langchain import ExecutorUsingLangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make a error handling dataset or error handling prompt, make sure the data entity has: `db_id`, `db_path` and existing `prompt` which was used earlier to generate results from the model.  Let's see an example to understand this better. We will be using our standard BirdBench dataset for this. We also define our generators in this case it will be [Prem-1B-SQL](https://huggingface.co/premai-io/prem-1B-SQL) model and a DB executor from langchain. \n",
    "\n",
    "You are't aware of generators, executors and datasets then you can check out the following:\n",
    "\n",
    "1. [Datasets tutorial](/examples/datasets.ipynb)\n",
    "2. [Generators tutorial](/examples/generators.ipynb)\n",
    "3. [Executors and evaluators tutorial](/examples/evaluation.ipynb)\n",
    "\n",
    "Since we are making a error dataset, so we will be using existing datasets. Because our goal is to transform the existing train datasets to a error handling datasets. \n",
    "\n",
    "The flow is simple:\n",
    "\n",
    "### For training\n",
    "\n",
    "1. Start with a exising datasets which is compatible with premsql datasets. \n",
    "2. Then use a generator to run on that dataset. The executor will gather errors for in-correct generations. \n",
    "3. Now use the existing response, initial prompt and the error to create the new data points which will be now using a error handling prompt. \n",
    "\n",
    "### For Inference\n",
    "\n",
    "premsql already handles automatic error handling in the [simple-pipeline](/premsql/pipelines/simple.py) and [execution guided decoding](/examples/generators.ipynb) section. So that you do not need to worry about that. \n",
    "\n",
    "\n",
    "Now let's start with defining our generators and execuror first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 09:15:05,666 - [GENERATOR] - INFO - Experiment folder found in: experiments/train/testing_error_gen\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.20s/it]\n"
     ]
    }
   ],
   "source": [
    "generator = Text2SQLGeneratorHF(\n",
    "    model_or_name_or_path=\"premai-io/prem-1B-SQL\",\n",
    "    experiment_name=\"testing_error_gen\",\n",
    "    type=\"train\", # do not type: 'test' since this will be used during training\n",
    "    device=\"cuda:0\"\n",
    ")\n",
    "\n",
    "executor = ExecutorUsingLangChain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this we define our existing training dataset. We are using BirdBench dataset but you can also use your own text2sql compatible datasets or any of our existing datasets. For demo purposes, we have set `num_rows` to 10, but in actual scenerio you should be using full length of the training datasets. Because generally your error dataset will be lesser than the length of the training dataset if you are using a descent trained model which can generate SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 09:15:12,907 - [BIRD-DATASET] - INFO - Loaded Bird Dataset\n",
      "2024-09-07 09:15:12,908 - [BIRD-DATASET] - INFO - Setting up Bird Dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying prompt: 100%|██████████| 10/10 [00:00<00:00, 2803.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from premsql.datasets import BirdDataset\n",
    "\n",
    "bird_train = BirdDataset(\n",
    "    split=\"train\",\n",
    "    dataset_folder=\"/root/anindya/text2sql/data\"\n",
    ").setup_dataset(\n",
    "    num_rows=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define our error handling dataset. It is simple, all you need is to feed in the generator of your choice and the executor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_dataset_gen = ErrorDatasetGenerator(\n",
    "    generator=generator,\n",
    "    executor=executor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate and save the results. You can use `force` if you want to force the generation once more. Once the error prompt creations are done, it will save the dataset inside `./experiments/train/<generator-experiment-name>/error_dataset.json`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating result ...:   0%|          | 0/10 [00:00<?, ?it/s]/root/miniconda3/envs/deep/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Generating result ...: 100%|██████████| 10/10 [00:23<00:00,  2.33s/it]\n",
      "2024-09-07 09:15:43,302 - [GENERATOR] - INFO - All responses are written to: experiments/train/testing_error_gen\n",
      "2024-09-07 09:15:43,303 - [ERROR-HANDLING-DATASET] - INFO - Starting Evaluation\n",
      "100%|██████████| 10/10 [00:29<00:00,  2.99s/it]\n",
      "2024-09-07 09:16:13,195 - [UTILS] - INFO - Saved JSON in: experiments/train/testing_error_gen/accuracy.json\n",
      "2024-09-07 09:16:13,197 - [UTILS] - INFO - Saved JSON in: experiments/train/testing_error_gen/predict.json\n",
      "Applying error prompt: 100%|██████████| 10/10 [00:00<00:00, 43873.47it/s]\n"
     ]
    }
   ],
   "source": [
    "error_dataset = error_dataset_gen.generate_and_save(\n",
    "    datasets=bird_train,\n",
    "    force=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once generations are fininshed, this is how a sample datapoint would look like. The `prompt` key will now contain error handling prompt. This is how the error_prompt template looks like:\n",
    "\n",
    "\n",
    "```python\n",
    "ERROR_HANDLING_PROMPT = \"\"\"\n",
    "{existing_prompt}\n",
    "\n",
    "# Generated SQL: {sql}\n",
    "\n",
    "## Error Message\n",
    "\n",
    "{error_msg}\n",
    "\n",
    "Carefully review the original question and error message, then rewrite the SQL query to address the identified issues. \n",
    "Ensure your corrected query uses correct column names, \n",
    "follows proper SQL syntax, and accurately answers the original question \n",
    "without introducing new errors.\n",
    "\n",
    "# SQL: \n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "You can also change the prompt by the following method:\n",
    "\n",
    "```python\n",
    "error_dataset = error_dataset_gen.generate_and_save(\n",
    "    datasets=bird_train,\n",
    "    force=True,\n",
    "    prompt_template=your_prompt_template\n",
    ")\n",
    "```\n",
    "\n",
    "Make sure your prompt template should atleast contain the four keys as laid down by the default error handling prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'db_id': 'movie_platform',\n",
       " 'question': 'Name movie titles released in year 1945. Sort the listing by the descending order of movie popularity.',\n",
       " 'SQL': 'SELECT movie_title FROM movies WHERE movie_release_year = 1945 ORDER BY movie_popularity DESC LIMIT 1',\n",
       " 'prompt': '\\n# Follow these instruction:\\nYou will be given schemas of tables of a database. Your job is to write correct\\nerror free SQL query based on the question asked. Please make sure:\\n\\n1. Do not add ``` at start / end of the query. It should be a single line query in a  single line (string format)\\n2. Make sure the column names are correct and exists in the table\\n3. For column names which has a space with it, make sure you have put `` in that column name\\n4. Think step by step and always check schema and question and the column names before writing the\\nquery. \\n\\n# Database and Table Schema:\\nCREATE TABLE \"lists\"\\n(\\n    user_id                     INTEGER\\n        references lists_users (user_id),\\n    list_id                     INTEGER not null\\n        primary key,\\n    list_title                  TEXT,\\n    list_movie_number           INTEGER,\\n    list_update_timestamp_utc   TEXT,\\n    list_creation_timestamp_utc TEXT,\\n    list_followers              INTEGER,\\n    list_url                    TEXT,\\n    list_comments               INTEGER,\\n    list_description            TEXT,\\n    list_cover_image_url        TEXT,\\n    list_first_image_url        TEXT,\\n    list_second_image_url       TEXT,\\n    list_third_image_url        TEXT\\n)\\nCREATE TABLE \"movies\"\\n(\\n    movie_id             INTEGER not null\\n        primary key,\\n    movie_title          TEXT,\\n    movie_release_year   INTEGER,\\n    movie_url            TEXT,\\n    movie_title_language TEXT,\\n    movie_popularity     INTEGER,\\n    movie_image_url      TEXT,\\n    director_id          TEXT,\\n    director_name        TEXT,\\n    director_url         TEXT\\n)\\nCREATE TABLE \"ratings_users\"\\n(\\n    user_id                 INTEGER\\n        references lists_users (user_id),\\n    rating_date_utc         TEXT,\\n    user_trialist           INTEGER,\\n    user_subscriber         INTEGER,\\n    user_avatar_image_url   TEXT,\\n    user_cover_image_url    TEXT,\\n    user_eligible_for_trial INTEGER,\\n    user_has_payment_method INTEGER\\n)\\nCREATE TABLE lists_users\\n(\\n    user_id                 INTEGER not null ,\\n    list_id                 INTEGER not null ,\\n    list_update_date_utc    TEXT,\\n    list_creation_date_utc  TEXT,\\n    user_trialist           INTEGER,\\n    user_subscriber         INTEGER,\\n    user_avatar_image_url   TEXT,\\n    user_cover_image_url    TEXT,\\n    user_eligible_for_trial TEXT,\\n    user_has_payment_method TEXT,\\n    primary key (user_id, list_id),\\n    foreign key (list_id) references lists(list_id),\\n    foreign key (user_id) references lists(user_id)\\n)\\nCREATE TABLE ratings\\n(\\n    movie_id                INTEGER,\\n    rating_id               INTEGER,\\n    rating_url              TEXT,\\n    rating_score            INTEGER,\\n    rating_timestamp_utc    TEXT,\\n    critic                  TEXT,\\n    critic_likes            INTEGER,\\n    critic_comments         INTEGER,\\n    user_id                 INTEGER,\\n    user_trialist           INTEGER,\\n    user_subscriber         INTEGER,\\n    user_eligible_for_trial INTEGER,\\n    user_has_payment_method INTEGER,\\n    foreign key (movie_id) references movies(movie_id),\\n    foreign key (user_id) references lists_users(user_id),\\n    foreign key (rating_id) references ratings(rating_id),\\n    foreign key (user_id) references ratings_users(user_id)\\n)\\n\\n\\n\\n# Here are some Examples on how to generate SQL statements and use column names:\\n\\n\\n# Question: Name movie titles released in year 1945. Sort the listing by the descending order of movie popularity.\\n\\n# Generated SQL: SELECT movie_title FROM movies WHERE movie_release_year = 1945 ORDER BY movie_popularity DESC LIMIT 1;\\n\\n## Error Message\\n\\nNone\\n\\nCarefully review the original question and error message, then rewrite the SQL query to address the identified issues. \\nEnsure your corrected query uses correct column names, \\nfollows proper SQL syntax, and accurately answers the original question \\nwithout introducing new errors.\\n\\n# SQL: \\n',\n",
       " 'db_path': '/root/anindya/text2sql/data/bird/train/train_databases/movie_platform/movie_platform.sqlite'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not need to run the error handling pipeline again and again once you have generated them once. The next time you require this dataset (most probably to use it during fine-tuning) you just need to use `from_existing` class method. \n",
    "\n",
    "It requires `experiment_name` as an required argument. Make sure that experiment exists. It is the same experiment name which was used in the generators that was used for error handling dataset generations. Here is an example below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'db_id': 'movie_platform', 'question': 'Name movie titles released in year 1945. Sort the listing by the descending order of movie popularity.', 'SQL': 'SELECT movie_title FROM movies WHERE movie_release_year = 1945 ORDER BY movie_popularity DESC LIMIT 1', 'prompt': '\\n# Follow these instruction:\\nYou will be given schemas of tables of a database. Your job is to write correct\\nerror free SQL query based on the question asked. Please make sure:\\n\\n1. Do not add ``` at start / end of the query. It should be a single line query in a  single line (string format)\\n2. Make sure the column names are correct and exists in the table\\n3. For column names which has a space with it, make sure you have put `` in that column name\\n4. Think step by step and always check schema and question and the column names before writing the\\nquery. \\n\\n# Database and Table Schema:\\nCREATE TABLE \"lists\"\\n(\\n    user_id                     INTEGER\\n        references lists_users (user_id),\\n    list_id                     INTEGER not null\\n        primary key,\\n    list_title                  TEXT,\\n    list_movie_number           INTEGER,\\n    list_update_timestamp_utc   TEXT,\\n    list_creation_timestamp_utc TEXT,\\n    list_followers              INTEGER,\\n    list_url                    TEXT,\\n    list_comments               INTEGER,\\n    list_description            TEXT,\\n    list_cover_image_url        TEXT,\\n    list_first_image_url        TEXT,\\n    list_second_image_url       TEXT,\\n    list_third_image_url        TEXT\\n)\\nCREATE TABLE \"movies\"\\n(\\n    movie_id             INTEGER not null\\n        primary key,\\n    movie_title          TEXT,\\n    movie_release_year   INTEGER,\\n    movie_url            TEXT,\\n    movie_title_language TEXT,\\n    movie_popularity     INTEGER,\\n    movie_image_url      TEXT,\\n    director_id          TEXT,\\n    director_name        TEXT,\\n    director_url         TEXT\\n)\\nCREATE TABLE \"ratings_users\"\\n(\\n    user_id                 INTEGER\\n        references lists_users (user_id),\\n    rating_date_utc         TEXT,\\n    user_trialist           INTEGER,\\n    user_subscriber         INTEGER,\\n    user_avatar_image_url   TEXT,\\n    user_cover_image_url    TEXT,\\n    user_eligible_for_trial INTEGER,\\n    user_has_payment_method INTEGER\\n)\\nCREATE TABLE lists_users\\n(\\n    user_id                 INTEGER not null ,\\n    list_id                 INTEGER not null ,\\n    list_update_date_utc    TEXT,\\n    list_creation_date_utc  TEXT,\\n    user_trialist           INTEGER,\\n    user_subscriber         INTEGER,\\n    user_avatar_image_url   TEXT,\\n    user_cover_image_url    TEXT,\\n    user_eligible_for_trial TEXT,\\n    user_has_payment_method TEXT,\\n    primary key (user_id, list_id),\\n    foreign key (list_id) references lists(list_id),\\n    foreign key (user_id) references lists(user_id)\\n)\\nCREATE TABLE ratings\\n(\\n    movie_id                INTEGER,\\n    rating_id               INTEGER,\\n    rating_url              TEXT,\\n    rating_score            INTEGER,\\n    rating_timestamp_utc    TEXT,\\n    critic                  TEXT,\\n    critic_likes            INTEGER,\\n    critic_comments         INTEGER,\\n    user_id                 INTEGER,\\n    user_trialist           INTEGER,\\n    user_subscriber         INTEGER,\\n    user_eligible_for_trial INTEGER,\\n    user_has_payment_method INTEGER,\\n    foreign key (movie_id) references movies(movie_id),\\n    foreign key (user_id) references lists_users(user_id),\\n    foreign key (rating_id) references ratings(rating_id),\\n    foreign key (user_id) references ratings_users(user_id)\\n)\\n\\n\\n\\n# Here are some Examples on how to generate SQL statements and use column names:\\n\\n\\n# Question: Name movie titles released in year 1945. Sort the listing by the descending order of movie popularity.\\n\\n# Generated SQL: SELECT movie_title FROM movies WHERE movie_release_year = 1945 ORDER BY movie_popularity DESC LIMIT 1;\\n\\n## Error Message\\n\\nNone\\n\\nCarefully review the original question and error message, then rewrite the SQL query to address the identified issues. \\nEnsure your corrected query uses correct column names, \\nfollows proper SQL syntax, and accurately answers the original question \\nwithout introducing new errors.\\n\\n# SQL: \\n', 'db_path': '/root/anindya/text2sql/data/bird/train/train_databases/movie_platform/movie_platform.sqlite'}\n"
     ]
    }
   ],
   "source": [
    "existing_error_dataset = ErrorDatasetGenerator.from_existing(\n",
    "    experiment_name=\"testing_error_gen\"\n",
    ")\n",
    "\n",
    "print(existing_error_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even tokenize the entities as well if you want. Right now we only support huggingface transformers tokenizers to tokenize the error dataset during the time of loading. This is how we do it while loading an existing dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 09:21:15,995 - [DATASET] - INFO - Casted dataset with model chat template\n",
      "2024-09-07 09:21:15,996 - [DATASET] - INFO - Starting Tokenization ...\n",
      "Tokenizing:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|██████████| 10/10 [00:00<00:00, 160.05it/s]\n",
      "Tokenizing: 100%|██████████| 10/10 [00:00<00:00, 181.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([32013, 32013,  2042,  ...,   207,    16, 32021]),\n",
       " 'labels': tensor([ -100,  -100,  -100,  ...,   207,    16, 32021]),\n",
       " 'raw': {'db_id': 'movie_platform',\n",
       "  'question': 'Name movie titles released in year 1945. Sort the listing by the descending order of movie popularity.',\n",
       "  'SQL': 'SELECT movie_title FROM movies WHERE movie_release_year = 1945 ORDER BY movie_popularity DESC LIMIT 1',\n",
       "  'prompt': '<｜begin▁of▁sentence｜>You are an AI programming assistant, utilizing the Deepseek Coder model, developed by Deepseek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer\\n### Instruction:\\n\\n# Follow these instruction:\\nYou will be given schemas of tables of a database. Your job is to write correct\\nerror free SQL query based on the question asked. Please make sure:\\n\\n1. Do not add ``` at start / end of the query. It should be a single line query in a  single line (string format)\\n2. Make sure the column names are correct and exists in the table\\n3. For column names which has a space with it, make sure you have put `` in that column name\\n4. Think step by step and always check schema and question and the column names before writing the\\nquery. \\n\\n# Database and Table Schema:\\nCREATE TABLE \"lists\"\\n(\\n    user_id                     INTEGER\\n        references lists_users (user_id),\\n    list_id                     INTEGER not null\\n        primary key,\\n    list_title                  TEXT,\\n    list_movie_number           INTEGER,\\n    list_update_timestamp_utc   TEXT,\\n    list_creation_timestamp_utc TEXT,\\n    list_followers              INTEGER,\\n    list_url                    TEXT,\\n    list_comments               INTEGER,\\n    list_description            TEXT,\\n    list_cover_image_url        TEXT,\\n    list_first_image_url        TEXT,\\n    list_second_image_url       TEXT,\\n    list_third_image_url        TEXT\\n)\\nCREATE TABLE \"movies\"\\n(\\n    movie_id             INTEGER not null\\n        primary key,\\n    movie_title          TEXT,\\n    movie_release_year   INTEGER,\\n    movie_url            TEXT,\\n    movie_title_language TEXT,\\n    movie_popularity     INTEGER,\\n    movie_image_url      TEXT,\\n    director_id          TEXT,\\n    director_name        TEXT,\\n    director_url         TEXT\\n)\\nCREATE TABLE \"ratings_users\"\\n(\\n    user_id                 INTEGER\\n        references lists_users (user_id),\\n    rating_date_utc         TEXT,\\n    user_trialist           INTEGER,\\n    user_subscriber         INTEGER,\\n    user_avatar_image_url   TEXT,\\n    user_cover_image_url    TEXT,\\n    user_eligible_for_trial INTEGER,\\n    user_has_payment_method INTEGER\\n)\\nCREATE TABLE lists_users\\n(\\n    user_id                 INTEGER not null ,\\n    list_id                 INTEGER not null ,\\n    list_update_date_utc    TEXT,\\n    list_creation_date_utc  TEXT,\\n    user_trialist           INTEGER,\\n    user_subscriber         INTEGER,\\n    user_avatar_image_url   TEXT,\\n    user_cover_image_url    TEXT,\\n    user_eligible_for_trial TEXT,\\n    user_has_payment_method TEXT,\\n    primary key (user_id, list_id),\\n    foreign key (list_id) references lists(list_id),\\n    foreign key (user_id) references lists(user_id)\\n)\\nCREATE TABLE ratings\\n(\\n    movie_id                INTEGER,\\n    rating_id               INTEGER,\\n    rating_url              TEXT,\\n    rating_score            INTEGER,\\n    rating_timestamp_utc    TEXT,\\n    critic                  TEXT,\\n    critic_likes            INTEGER,\\n    critic_comments         INTEGER,\\n    user_id                 INTEGER,\\n    user_trialist           INTEGER,\\n    user_subscriber         INTEGER,\\n    user_eligible_for_trial INTEGER,\\n    user_has_payment_method INTEGER,\\n    foreign key (movie_id) references movies(movie_id),\\n    foreign key (user_id) references lists_users(user_id),\\n    foreign key (rating_id) references ratings(rating_id),\\n    foreign key (user_id) references ratings_users(user_id)\\n)\\n\\n\\n\\n# Here are some Examples on how to generate SQL statements and use column names:\\n\\n\\n# Question: Name movie titles released in year 1945. Sort the listing by the descending order of movie popularity.\\n\\n# Generated SQL: SELECT movie_title FROM movies WHERE movie_release_year = 1945 ORDER BY movie_popularity DESC LIMIT 1;\\n\\n## Error Message\\n\\nNone\\n\\nCarefully review the original question and error message, then rewrite the SQL query to address the identified issues. \\nEnsure your corrected query uses correct column names, \\nfollows proper SQL syntax, and accurately answers the original question \\nwithout introducing new errors.\\n\\n# SQL: \\n\\n',\n",
       "  'db_path': '/root/anindya/text2sql/data/bird/train/train_databases/movie_platform/movie_platform.sqlite'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Even tokenize this\n",
    "\n",
    "existing_error_dataset = ErrorDatasetGenerator.from_existing(\n",
    "    experiment_name=\"testing_error_gen\",\n",
    "    tokenize_model_name_or_path=\"premai-io/prem-1B-SQL\",\n",
    ")\n",
    "\n",
    "existing_error_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another example using sqlite executor\n",
    "\n",
    "This is an another example which uses sqlite executor to do the same thing as done above. This shows how easy it is to plug and play the components and customize it accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 09:21:27,223 - [GENERATOR] - INFO - Experiment folder found in: experiments/train/testing_error_sqlite\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.90s/it]\n"
     ]
    }
   ],
   "source": [
    "from premsql.evaluator.from_sqlite import SQLiteExecutor\n",
    "\n",
    "generator = Text2SQLGeneratorHF(\n",
    "    model_or_name_or_path=\"premai-io/prem-1B-SQL\",\n",
    "    experiment_name=\"testing_error_sqlite\",\n",
    "    type=\"train\",\n",
    "    device=\"cuda:0\"\n",
    ")\n",
    "sqlite_executor = SQLiteExecutor()\n",
    "\n",
    "error_dataset_gen = ErrorDatasetGenerator(\n",
    "    generator=generator,\n",
    "    executor=sqlite_executor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also generate a tokenized dataset on the fly. Here is how you do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating result ...:   0%|          | 0/10 [00:00<?, ?it/s]/root/miniconda3/envs/deep/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "Generating result ...: 100%|██████████| 10/10 [00:22<00:00,  2.22s/it]\n",
      "2024-09-07 09:22:09,232 - [GENERATOR] - INFO - All responses are written to: experiments/train/testing_error_sqlite\n",
      "2024-09-07 09:22:09,233 - [ERROR-HANDLING-DATASET] - INFO - Starting Evaluation\n",
      "100%|██████████| 10/10 [00:29<00:00,  2.91s/it]\n",
      "2024-09-07 09:22:38,359 - [UTILS] - INFO - Saved JSON in: experiments/train/testing_error_sqlite/accuracy.json\n",
      "2024-09-07 09:22:38,361 - [UTILS] - INFO - Saved JSON in: experiments/train/testing_error_sqlite/predict.json\n",
      "Applying error prompt: 100%|██████████| 10/10 [00:00<00:00, 44104.14it/s]\n",
      "2024-09-07 09:22:38,583 - [DATASET] - INFO - Casted dataset with model chat template\n",
      "2024-09-07 09:22:38,584 - [DATASET] - INFO - Starting Tokenization ...\n",
      "Tokenizing: 100%|██████████| 10/10 [00:00<00:00, 158.85it/s]\n",
      "Tokenizing: 100%|██████████| 10/10 [00:00<00:00, 182.43it/s]\n"
     ]
    }
   ],
   "source": [
    "error_dataset_from_sqlite = error_dataset_gen.generate_and_save(\n",
    "    datasets=bird_train,\n",
    "    tokenize=True,\n",
    "    force=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([32013, 32013,  2042,  ...,   207,    16, 32021]),\n",
       " 'labels': tensor([ -100,  -100,  -100,  ...,   207,    16, 32021]),\n",
       " 'raw': {'db_id': 'movie_platform',\n",
       "  'question': 'Name movie titles released in year 1945. Sort the listing by the descending order of movie popularity.',\n",
       "  'SQL': 'SELECT movie_title FROM movies WHERE movie_release_year = 1945 ORDER BY movie_popularity DESC LIMIT 1',\n",
       "  'prompt': '<｜begin▁of▁sentence｜>You are an AI programming assistant, utilizing the Deepseek Coder model, developed by Deepseek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer\\n### Instruction:\\n\\n# Follow these instruction:\\nYou will be given schemas of tables of a database. Your job is to write correct\\nerror free SQL query based on the question asked. Please make sure:\\n\\n1. Do not add ``` at start / end of the query. It should be a single line query in a  single line (string format)\\n2. Make sure the column names are correct and exists in the table\\n3. For column names which has a space with it, make sure you have put `` in that column name\\n4. Think step by step and always check schema and question and the column names before writing the\\nquery. \\n\\n# Database and Table Schema:\\nCREATE TABLE \"lists\"\\n(\\n    user_id                     INTEGER\\n        references lists_users (user_id),\\n    list_id                     INTEGER not null\\n        primary key,\\n    list_title                  TEXT,\\n    list_movie_number           INTEGER,\\n    list_update_timestamp_utc   TEXT,\\n    list_creation_timestamp_utc TEXT,\\n    list_followers              INTEGER,\\n    list_url                    TEXT,\\n    list_comments               INTEGER,\\n    list_description            TEXT,\\n    list_cover_image_url        TEXT,\\n    list_first_image_url        TEXT,\\n    list_second_image_url       TEXT,\\n    list_third_image_url        TEXT\\n)\\nCREATE TABLE \"movies\"\\n(\\n    movie_id             INTEGER not null\\n        primary key,\\n    movie_title          TEXT,\\n    movie_release_year   INTEGER,\\n    movie_url            TEXT,\\n    movie_title_language TEXT,\\n    movie_popularity     INTEGER,\\n    movie_image_url      TEXT,\\n    director_id          TEXT,\\n    director_name        TEXT,\\n    director_url         TEXT\\n)\\nCREATE TABLE \"ratings_users\"\\n(\\n    user_id                 INTEGER\\n        references lists_users (user_id),\\n    rating_date_utc         TEXT,\\n    user_trialist           INTEGER,\\n    user_subscriber         INTEGER,\\n    user_avatar_image_url   TEXT,\\n    user_cover_image_url    TEXT,\\n    user_eligible_for_trial INTEGER,\\n    user_has_payment_method INTEGER\\n)\\nCREATE TABLE lists_users\\n(\\n    user_id                 INTEGER not null ,\\n    list_id                 INTEGER not null ,\\n    list_update_date_utc    TEXT,\\n    list_creation_date_utc  TEXT,\\n    user_trialist           INTEGER,\\n    user_subscriber         INTEGER,\\n    user_avatar_image_url   TEXT,\\n    user_cover_image_url    TEXT,\\n    user_eligible_for_trial TEXT,\\n    user_has_payment_method TEXT,\\n    primary key (user_id, list_id),\\n    foreign key (list_id) references lists(list_id),\\n    foreign key (user_id) references lists(user_id)\\n)\\nCREATE TABLE ratings\\n(\\n    movie_id                INTEGER,\\n    rating_id               INTEGER,\\n    rating_url              TEXT,\\n    rating_score            INTEGER,\\n    rating_timestamp_utc    TEXT,\\n    critic                  TEXT,\\n    critic_likes            INTEGER,\\n    critic_comments         INTEGER,\\n    user_id                 INTEGER,\\n    user_trialist           INTEGER,\\n    user_subscriber         INTEGER,\\n    user_eligible_for_trial INTEGER,\\n    user_has_payment_method INTEGER,\\n    foreign key (movie_id) references movies(movie_id),\\n    foreign key (user_id) references lists_users(user_id),\\n    foreign key (rating_id) references ratings(rating_id),\\n    foreign key (user_id) references ratings_users(user_id)\\n)\\n\\n\\n\\n# Here are some Examples on how to generate SQL statements and use column names:\\n\\n\\n# Question: Name movie titles released in year 1945. Sort the listing by the descending order of movie popularity.\\n\\n# Generated SQL: SELECT movie_title FROM movies WHERE movie_release_year = 1945 ORDER BY movie_popularity DESC LIMIT 1;\\n\\n## Error Message\\n\\nNone\\n\\nCarefully review the original question and error message, then rewrite the SQL query to address the identified issues. \\nEnsure your corrected query uses correct column names, \\nfollows proper SQL syntax, and accurately answers the original question \\nwithout introducing new errors.\\n\\n# SQL: \\n\\n',\n",
       "  'db_path': '/root/anindya/text2sql/data/bird/train/train_databases/movie_platform/movie_platform.sqlite'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_dataset_from_sqlite[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats it, that is how you generate a error handling dataset. This dataset will be compatible with other premsql datasets. So you can use / mix all of them to use as a singular dataset entity which can be now used collectively for fine-tuning purposes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
